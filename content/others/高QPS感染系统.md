# 高QPS消息队列ShopId过滤与分布式系统一致性设计报告

## 1. 执行摘要

本报告旨在解决一个核心挑战：在接收每秒10万次查询（QPS）的消息队列中，高效地根据一个包含数百个可变动的`ShopId`列表进行消息过滤，并确保该`ShopId`列表在超过10台服务器组成的分布式系统中保持实时一致性，同时最大限度地降低系统资源消耗。

所提出的解决方案核心在于结合内存中的高速查找机制与实时数据同步管道。具体而言，每个应用服务器将维护一个本地的、内存中的`HashSet`用于`ShopId`的快速查找。`ShopId`列表的变动将通过基于MySQL二进制日志（binlog）的变更数据捕获（CDC）工具Debezium进行实时捕获，并通过Apache Kafka作为可靠的消息骨干网进行分发。每个应用服务器上的Kafka消费者将订阅这些变更事件，并实时更新其本地`HashSet`。

该架构设计具有多重优势：它能够满足每秒10万次查询的吞吐量需求，显著降低系统资源消耗，确保分布式节点间的数据强一致性，并为未来的系统扩展提供了坚实基础。

## 2. 问题陈述与需求分析

当前系统面临的核心问题是如何在极高的消息吞吐量下，高效且一致地处理`ShopId`的过滤逻辑。

### 高吞吐量消息处理需求

用户系统需要处理每秒10万次查询（QPS）的消息流。每条传入消息都需要提取`ShopId`，并与系统内部维护的动态`ShopId`列表进行比对。这种高吞吐量对`ShopId`验证步骤的延迟提出了极其严格的要求，任何涉及每条消息的网络I/O或磁盘访问的操作都将成为性能瓶颈。例如，L1缓存的访问时间约为0.5纳秒，而同一数据中心内的往返时间高达500,000纳秒（0.5毫秒）。这种数量级的差异表明，在每秒10万次查询的压力下，直接的数据库查找将迅速使数据库过载，并引入不可接受的延迟。因此，为了满足性能目标，  

`ShopId`的验证必须在内存中完成。

### 动态且相对较小的`ShopId`集合

系统内部持有的`ShopId`列表数量为“数百个”，并且该列表是可变动的，存储在MySQL数据库中。这种可变性是关键因素，意味着`ShopId`的任何变更（新增或删除）都必须迅速且一致地传播到所有处理节点。然而，该列表的“数百个”规模相对较小，这使得将整个数据集完整地加载到每个应用服务器的内存中成为可能，从而避免了对外部共享缓存的依赖，简化了架构并进一步降低了延迟。

### 分布式系统环境

系统部署在超过10台服务器上，形成一个分布式环境。这种分布式特性引入了维护所有节点数据一致性的复杂性，并要求确保`ShopId`的变动能够及时、统一地被整个集群感知。中央数据源（MySQL）的变更需要可靠且迅速地反映到所有分布式缓存中。

### 核心目标

本设计的核心目标是：

1. **最小化系统资源消耗**：在`ShopId`检查过程中，最大限度地减少CPU、内存和I/O的开销。
2. **确保及时一致性**：保证`ShopId`的变动能够及时、一致地传播到所有服务器。
3. **维持高吞吐量**：在满足上述条件的同时，保持每秒10万次查询的消息处理能力。

## 3. 架构概述：内存缓存与实时同步

为了满足高吞吐量和低延迟的`ShopId`过滤需求，同时解决分布式系统中的数据一致性问题，本报告提出了一种结合内存缓存和实时变更数据捕获（CDC）的架构。

### 内存查找的合理性

为了满足每秒10万次查询的严格性能要求，`ShopId`的验证必须以极低的延迟完成。任何涉及网络I/O或磁盘访问的操作都会引入显著的瓶颈。例如，一次磁盘寻道需要10,000,000纳秒（10毫秒），通过1Gbps网络读取2KB数据需要20,000纳秒（20微秒），而L1缓存的访问时间仅为0.5纳秒。这种巨大的性能差异清楚地表明，只有内存中的查找才能达到所需的处理速度。  

考虑到`ShopId`的数量仅为“数百个”，整个数据集可以轻松地存储在每个应用服务器的本地内存中。这种设计避免了使用独立的外部分布式缓存层（例如Redis集群）的需要。虽然外部缓存对于处理更大规模的数据集或需要共享状态的场景非常有用，但对于本用例而言，在每个服务器上维护一个本地内存副本可以简化架构，减少查找过程中的网络跳数，并规避管理额外分布式服务所带来的运维开销和潜在瓶颈。这种设计选择直接有助于最小化系统资源消耗并最大化查找性能。通过将数据本地化，每个服务器的`ShopId`检查完全在本地进行，消除了网络延迟和与其他服务器争用缓存访问的可能，从而进一步提升了效率和系统稳定性。

### 高级架构方案

所提出的架构由以下核心组件构成：

- **应用服务器**：每台应用服务器（超过10台）将维护一个本地的、内存中的`HashSet<ShopId>`。这个`HashSet`将作为验证传入`ShopId`的权威数据源。

- **MySQL数据库**：作为可变`ShopId`列表的中央权威存储库。所有变更（新增、删除）都源自此处。

- **变更数据捕获（CDC）层（Debezium）**：部署Debezium连接器，持续监控并捕获MySQL数据库二进制日志（binlog）中的行级变更（插入、更新、删除）。  

- **消息骨干网（Apache Kafka）**：Debezium将捕获到的`ShopId`变更事件发布到专门的Apache Kafka主题。Kafka作为高度可扩展、持久化且有序的事件流，确保了变更的可靠传播。  

- **同步机制**：每个应用服务器都将运行一个Kafka消费者，订阅`ShopId`变更主题。一旦接收到事件，消费者将实时更新其本地内存中的`HashSet`，确保所有服务器都维护着一致且最新的`ShopId`视图。

## 4. 优化内存中的`ShopId`查找

为了实现每秒10万次查询的性能目标，对`ShopId`进行高效的内存查找至关重要。

### 数据结构选择：`HashSet`实现O(1)平均时间复杂度

对于高效检查`ShopId`是否存在的核心任务，`HashSet`是最佳选择。它利用哈希表，为`contains()`操作提供了平均O(1)的时间复杂度。这意味着查找时间与  

`ShopId`的数量无关，从而实现了极快的速度。基准测试表明，`HashSet.contains()`的性能比`ArrayList.contains()`快几个数量级。  

Java的`HashSet`（及其底层的`HashMap`）通过链表或在Java 8+中对高冲突桶使用平衡树等技术智能地处理哈希冲突。这种健壮的冲突处理机制确保了性能很少会退化到理论上的最坏情况O(N)，特别是对于分布良好的哈希函数和仅有“数百个”  

`ShopId`的数据集。

对于“数百个”`ShopId`（可能为整数或短字符串），`HashSet`的内存消耗将非常小，可以轻松地适应每个应用服务器的分配内存，而不会造成内存压力或需要对JVM堆进行超出标准最佳实践的显著调优。

虽然布隆过滤器（Bloom Filter）因其极高的空间效率常被考虑用于成员测试，但它们存在误报的可能性且不支持删除操作。对于“数百个”  

`ShopId`的数据集而言，布隆过滤器相对于`HashSet`所提供的内存节省微不足道。更重要的是，`HashSet`的确定性（无误报）确保了业务逻辑的过滤始终是准确的，避免了概率性结果可能引入的复杂性和潜在错误。这种选择优先考虑了正确性和操作简便性，同时在给定规模下不牺牲性能。

下表对几种常见的内存数据结构在`ShopId`查找场景下的适用性进行了比较：

**表1：内存中`ShopId`查找数据结构比较**

| 数据结构       | 平均查找时间复杂度 | 最坏查找时间复杂度 | 内存效率（相对） | 可能出现误报 | 支持删除 | 对“数百个”ID的适用性   |
| -------------- | ------------------ | ------------------ | ---------------- | ------------ | -------- | ---------------------- |
| `HashSet`      | O(1)               | O(N) (罕见)        | 中等             | 否           | 是       | 高度适用               |
| `Bloom Filter` | O(k)               | O(k)               | 高               | 是           | 否       | 不理想（用于精确检查） |
| `ArrayList`    | O(N)               | O(N)               | 低               | 否           | 是       | 不适用（对于10万QPS）  |
| `TreeSet`      | O(log N)           | O(log N)           | 中等             | 否           | 是       | 适用性低于`HashSet`    |

Export to Sheets

## 5. 使用变更数据捕获（CDC）实现`ShopId`实时同步

为了确保分布式系统中`ShopId`列表的及时和一致更新，采用基于日志的变更数据捕获（CDC）是关键。

### 为何选择基于日志的CDC？

基于日志的变更数据捕获（CDC）是实时跟踪和传播数据库变更的最有效且非侵入性方法。与传统的轮询机制（会持续对数据库产生查询负载）或数据库触发器（会增加每次事务的开销）不同，基于日志的CDC被动地读取数据库的事务日志（MySQL的二进制日志或binlog）。这种方法对源MySQL数据库的性能影响最小，因为它不干扰其主要的事务工作负载。  

数据库的事务日志是所有数据修改的持久化、有序且完整的记录。通过读取此日志，CDC确保不会遗漏任何`ShopId`更新，并且变更会按照它们在数据库中发生的精确顺序被捕获和处理。这对于维护分布式缓存中的数据一致性至关重要。  

采用基于日志的CDC从根本上解耦了应用程序对`ShopId`更新的需求与对MySQL数据库的直接交互。这是一个关键的架构转变。现在，超过10台应用服务器不再需要重复查询MySQL以检测变更，而是简单地从Kafka消费事件流。这可以防止MySQL数据库在主应用程序的高QPS负载下成为瓶颈，因为它免受持续的“变更检测”查询的影响。这种解耦是构建高度可扩展和弹性分布式系统的基石。

### Debezium和Kafka作为核心组件

- **Debezium**：这是一个开源的分布式平台，专门用于变更数据捕获。它作为一个连接器，监控MySQL数据库并从其二进制日志中捕获所有行级变更（插入、更新、删除）。对于MySQL，确保二进制日志已启用并配置为  

  `binlog_format=row`对于准确和详细的变更事件至关重要。Debezium将这些变更转换为标准化的事件流。  

- **Apache Kafka**：Kafka作为CDC管道的中央、健壮、可扩展且容错的消息骨干网。Debezium将捕获到的  

  `ShopId`变更事件发布到专门的Kafka主题。Kafka的关键优势在于其持久存储事件的能力、分区内有序交付的保证以及允许多个消费者独立并发读取的特性，这使其成为将`ShopId`更新可靠分发到所有10+应用服务器的理想选择。  

- **Kafka Connect**：Debezium通常作为Kafka Connect连接器部署。Kafka Connect是一个用于在Kafka与其他系统之间流式传输数据的框架，为CDC过程本身提供了内置的容错性、可伸缩性和管理能力。这确保了Debezium连接器始终运行并能从故障中恢复。  

Debezium和Kafka的结合不仅解决了实时缓存同步的眼前问题，还围绕`ShopId`变更建立了一个强大的“事件驱动架构”。这意味着任何其他下游系统或服务（例如，分析平台、审计日志、欺诈检测、电子商务的实时库存系统）都可以轻松订阅同一个Kafka主题，以响应`ShopId`修改，而无需自行与MySQL建立直接集成。这促进了企业范围内的数据一致性，减少了重复的集成工作，并使整个系统对于未来的业务需求更具敏捷性和可扩展性。  

### 初始加载策略

- **Debezium的初始快照**：当Debezium连接器首次启动时，或者其存储的偏移量失效时（例如，binlog在连接器读取之前被清除），它会对其配置的表执行初始一致性快照。在此阶段，Debezium会从MySQL读取所有现有的  

  `ShopId`，并将其作为事件流发布到指定的Kafka主题。这有效地通过数据库的当前状态“引导”了  

  `ShopId`变更流。

- **应用服务器引导**：每个应用服务器在启动（或恢复）时，都充当Kafka消费者。它订阅`ShopId`变更主题，并且至关重要的是，它会从头开始处理所有可用的消息（或者如果它是从优雅关闭中恢复，则从其上次提交的偏移量开始）。这确保了每个服务器在处理高吞吐量传入消息之前，能够迅速构建其本地  

  `HashSet`中`ShopId`的完整且一致的视图。

- **增量快照**：Debezium还支持增量快照，可以通过信号机制触发。这在之后需要向监控列表添加新表时非常有用，允许进行有针对性的快照，而无需重新启动整个连接器或重新快照所有表。  

这种初始加载机制对于系统的弹性伸缩和可靠性至关重要，特别是在拥有10多台服务器的分布式环境中。如果每台应用服务器在启动时都直接查询MySQL以获取完整的`ShopId`列表，将导致“惊群效应”（thundering herd problem），可能使数据库因并发读取请求而过载。通过将这种初始状态同步卸载到Kafka的持久化和高吞吐量日志，系统确保了快速且无中断的扩展，因为新服务器可以迅速独立地预热其缓存，而不会影响MySQL。这种设计上的前瞻性可以有效避免分布式系统常见的故障源。  

### 持续同步

- **Kafka消费者实现实时更新**：每个应用服务器将运行一个专用的Kafka消费者，持续轮询`ShopId`变更主题。该消费者将属于一个消费者组，从而实现  

  `ShopId`事件的分布式并行消费。

- **动态`HashSet`更新**：当Debezium从MySQL捕获新的`ShopId`添加、更新或删除并将其发布到Kafka时，应用消费者会实时接收这些事件。收到事件后，消费者将相应地更新其本地内存中的`HashSet`：对于新条目使用`ShopId.add()`，对于删除使用`ShopId.remove()`。对现有`ShopId`的更新（如果ID本身发生变化，这对于ID而言较不常见）通常会作为删除后添加来处理。

- **精确一次处理语义**：为了确保最高级别的缓存一致性并防止数据异常（例如缓存中`ShopId`的丢失或重复），Kafka消费者应配置为“精确一次处理”（EOS）语义。这通过幂等生产者（Debezium/Kafka Connect固有地处理）和将Kafka消费者配置为使用  

  `read_committed`隔离级别来实现。EOS保证即使在瞬时故障、重试或消费者组重新平衡的情况下，每个  

  `ShopId`变更事件也只会被精确地应用一次。

对缓存更新采用“精确一次处理”保证不仅仅是性能或效率特性；它对于业务逻辑的**正确性和完整性**至关重要。如果没有它，内存中“数百个”`ShopId`可能会随着时间或在不同节点之间变得不一致（例如，已删除的`ShopId`仍保留在缓存中，或新的`ShopId`被遗漏），从而导致不正确的过滤决策（处理本应丢弃的消息，或反之）。这可能导致重大的业务影响，例如处理无效订单或未能处理有效订单。

## 6. 处理分布式一致性与可靠性

在分布式系统中，维护数据一致性和确保系统可靠性是复杂但至关重要的任务。

### Kafka消费者组重新平衡

- **机制**：在Kafka消费者组中，主题的分区被分配给各个消费者。当消费者集合或分区发生变化时（例如，消费者加入或离开组、消费者失败或主题添加了新分区），就会发生“重新平衡”。在重新平衡期间，Kafka会重新分配分区，以确保活跃消费者之间的处理负载均衡。  

- **对有状态应用程序的影响**：重新平衡对像我们内存中`ShopId`缓存这样的有状态应用程序可能产生显著的副作用。传统的“急切”（eager）重新平衡协议可能导致“停顿世界”（stop the world）效应，即组中所有消费者暂时停止处理消息，从而增加延迟和处理暂停。更关键的是，对于维护本地状态（如我们的  

  `HashSet`）的应用程序，分区重新分配可能导致临时的数据不一致、潜在的重复处理甚至遗漏记录，如果处理不当。消费者可能会失去其先前处理的分区的拥有权，需要为新分配的分区重建或验证其本地状态。  

- **缓解策略**：

  - **`ConsumerRebalanceListener`**：这是有状态消费者的关键组件。必须实现`ConsumerRebalanceListener` 。  

    `onPartitionsRevoked()`方法在消费者失去其分区拥有权之前被调用。这是清除或使与已撤销分区关联的内存中`HashSet`部分失效（或如果`ShopId`未分区，则清除整个缓存）的理想位置。随后，当消费者获得其新的分区分配时，会调用`onPartitionsAssigned()`方法，允许它触发重新加载与这些新分区相关的`ShopId`，可以通过从Kafka重放或在必要时进行完整快照来完成。这确保了优雅的状态管理并最大限度地减少了不一致性。  

  - **协作式重新平衡**：尽可能将Kafka消费者组配置为使用“协作式”（cooperative）重新平衡协议。与急切式重新平衡不同，协作式重新平衡允许消费者在重新平衡期间继续处理未受影响的分区数据，从而最大限度地减少处理中断，并对分配过程提供更精细的控制。  

  - **粘性分区分配器**：将消费者组配置为使用粘性分区分配器（`org.apache.kafka.clients.consumer.StickyAssignor`）。此策略最大限度地减少了重新平衡期间分区在消费者之间的重新分配，确保分区尽可能地保留在同一消费者上。这显著减少了所需的数据重新加载和状态中断，对于有状态操作尤其有利。  

  - **参数调优**：仔细调整Kafka消费者参数，例如`session.timeout.ms`（消费者在被视为失败之前的最大不活跃时间）和`heartbeat.interval.ms`（消费者向组协调器发送心跳的频率）。适当的调优平衡了对实际消费者故障的响应速度与避免因瞬时网络问题或处理缓慢而导致不必要的重新平衡。  

Kafka的重新平衡虽然是容错和可伸缩性的基本特性，但对于像我们内存中`ShopId`缓存这样的有状态应用程序而言，它代表着一个重大的**操作挑战**。对于处理10万QPS的系统，任何因重新平衡导致的长时间暂停或不一致都可能直接导致消息积压、处理延迟增加或过滤错误。通过主动设计`ConsumerRebalanceListener`并利用优化的分配器和重新平衡协议，可以将潜在的一致性问题转化为可管理、弹性的过程，确保即使在动态条件下（例如，服务器故障、部署、扩展事件），高QPS流也不会受到显著中断，并且`ShopId`缓存保持准确。这使得系统从仅仅“工作”提升到“**可靠地**大规模工作”。

### CDC管道的容错性和高可用性

- **Kafka的持久性**：Apache Kafka旨在实现高持久性和可用性。它通过可配置的复制因子（例如，3个副本）将消息持久化存储在多个代理（broker）上。这确保即使单个Kafka代理发生故障，  

  `ShopId`变更事件也不会丢失。

- **Kafka Connect的弹性**：托管Debezium连接器的Kafka Connect框架本身具有容错性。如果Kafka Connect工作进程或Debezium连接器实例发生故障，Kafka Connect会自动检测到故障并在集群中另一个可用的工作进程上重新启动连接器。此机制确保了CDC过程的持续运行。  

- **Debezium的偏移量管理**：Debezium会仔细跟踪其在MySQL二进制日志（binlog）中的读取位置（偏移量）。这使得它能够在任何重启或故障后从上次已知的偏移量继续捕获变更，从而防止发布到Kafka的变更流中出现数据丢失或重复。  

整个CDC管道，从MySQL到应用程序的内存缓存，都设计了高可用性和容错性。这意味着即使单个组件（MySQL、Debezium、Kafka代理、Kafka Connect工作进程）发生瞬时故障，`ShopId`的变更也将继续流动并反映在应用程序缓存中。这种端到端弹性对于处理10万QPS的系统至关重要，因为它确保了“及时感知变更”不仅在理想条件下得到维持，而且在实际操作挑战中也得到维持。

### 解决潜在数据陈旧性与一致性模型

- **最终一致性**：在任何分布式系统中，所有节点之间实现真正的“即时”一致性几乎是不可能的。所提出的架构采用“最终一致性”模型。`ShopId`变更在MySQL中提交到其反映在所有应用服务器缓存中，总是存在一个很小的非零延迟。然而，对于调优良好的基于日志的CDC管道，这种延迟通常在毫秒级别。  

- **影响评估**：对于“数百个”`ShopId`的列表，其变更率（新增/删除）可能相对于10万QPS的消息流较低。因此，在变更传播过程中短暂的潜在不一致期对于大多数业务逻辑而言通常是可以接受的，特别是考虑到基于日志的CDC的快速性。这种以最小延迟换取显著更高吞吐量和降低数据库负载的权衡是非常有利的。

- **监控陈旧性**：持续监控Kafka消费者延迟（lag）至关重要。此指标直接指示应用程序消费者与  

  `ShopId`变更主题中最新消息的滞后程度。高延迟将表明CDC管道或消费者处理存在瓶颈，预示着缓存陈旧性增加。应为超出预定义阈值的延迟配置警报。

明确定义和传达“最终一致性”模型对于管理预期至关重要。尽管系统旨在实现“实时”，但承认固有的分布式系统权衡可以提供清晰度。更重要的是，持续监控允许团队量化`ShopId`传播的实际“及时性”（延迟），并确保其始终保持在可接受的服务水平协议（SLA）范围内。这使得一个抽象概念转变为可衡量的操作指标。

## 7. 性能调优与优化

为了确保系统能够以最小的资源消耗高效处理每秒10万次查询，需要对各个组件进行细致的性能调优。

### Kafka代理和主题配置

- **分区**：分区是Kafka中并行处理的基本单位。更多的分区可以实现生产者和消费者之间更高的并发写入和读取，直接转化为更高的吞吐量。  

  `ShopId`变更主题的分区数量应根据预期的变更事件峰值吞吐量和消费者实例（应用服务器）的数量仔细选择。略微过度分区也可以适应未来的增长，而不会破坏基于键的顺序保证。  

- **复制因子**：将`ShopId`主题的复制因子设置为至少3，以确保变更事件的高持久性和可用性。这意味着每条消息都存储在三个不同的Kafka代理上，从而在代理发生故障时保护数据不丢失。  

- **消息大小和批处理**：通过调整`batch.size`（批处理中的最大字节数）和`linger.ms`（等待累积消息的最长时间）来优化Kafka生产者配置（Debezium内部使用）。更大的批处理大小和更长的等待时间可以减少网络开销并提高吞吐量，尽管它们可能会稍微增加延迟。  

- **压缩**：在Kafka主题和生产者上启用消息压缩（例如，`lz4`）。这显著减少了网络带宽消耗和存储需求，可以提高整体吞吐量，特别是对于高容量数据流。  

Kafka基础设施的优化将广义上惠及所有数据流，包括这个关键的CDC流。一个调优良好的Kafka集群可以高效地处理主消息队列（如果它也使用Kafka）的10万QPS以及其他潜在的数据管道，确保`ShopId`更新在最小争用下得到处理。

### Debezium和Kafka Connect调优

- **Debezium参数**：Debezium的性能可以通过调整`snapshot.max.threads`、`snapshot.fetch.size`、`max.batch.size`、`max.queue.size`和`poll.interval.ms`等参数进行优化。通常，Debezium的默认性能相关属性在许多情况下表现良好。  

- **Kafka Connect参数**：Kafka Connect的性能可以通过调整`batch.size`、`linger.ms`和`compression.type`等参数进行优化。  

- **背压管理**：持续监控Kafka延迟（lag）并应用背压机制（如速率限制或批处理大小调整）以避免落后。  

- **存储I/O**：确保数据库和Kafka代理上都有足够的磁盘IOPS，因为CDC可能涉及大量的I/O操作。  

### 应用服务器优化

- **CPU和内存**：确保应用服务器拥有足够的CPU处理能力和内存来处理传入的10万QPS消息，并维护内存中的`ShopId` `HashSet`。PostgreSQL的性能调优提示也强调了CPU能力和内存的重要性。  

- **JVM调优**：对于Java应用程序，JVM垃圾回收（GC）策略的选择对性能有显著影响。对于低延迟要求，建议使用G1GC（`-XX:+UseG1GC`）。  

## 8. 结论与建议

本报告提出的架构设计，通过在每个应用服务器上部署内存中的`HashSet`进行`ShopId`的超高速查找，并结合基于Debezium和Kafka的实时变更数据捕获（CDC）管道进行`ShopId`列表的同步，能够高效地满足每秒10万次查询的消息过滤需求，同时最大限度地降低系统资源消耗并确保分布式系统中的数据一致性。

**核心优势总结：**

- **极致性能**：内存`HashSet`实现了O(1)的平均查找时间复杂度，能够轻松应对10万QPS的过滤需求，避免了昂贵的网络和磁盘I/O操作。
- **实时一致性**：基于日志的CDC（Debezium）以非侵入性方式捕获MySQL变更，并通过Kafka的持久化、有序事件流传播，确保所有分布式节点能够及时感知并更新`ShopId`列表。精确一次处理语义进一步保障了数据更新的准确性。
- **系统弹性**：Kafka的复制机制和Kafka Connect的容错能力确保了CDC管道的高可用性。对Kafka消费者组重新平衡的细致处理（通过`ConsumerRebalanceListener`、协作式重新平衡和粘性分配器）保障了在动态环境下的系统稳定性和缓存一致性。
- **资源最小化**：将`ShopId`列表完全加载到内存中，避免了对外部共享缓存的依赖，简化了架构，并降低了额外的基础设施和运维成本。CDC的非侵入性特性也保护了源MySQL数据库免受高负载影响。

**实施建议：**

1. **MySQL配置**：确保MySQL已启用二进制日志（binlog）且`binlog_format`设置为`row`，并授予Debezium连接器必要的权限。  

2. **Kafka集群规划**：根据预期的变更事件吞吐量（尽管`ShopId`变更频率可能不高，但整个Kafka集群需要考虑所有数据流），合理规划Kafka主题的分区数量和复制因子（建议至少为3）。  

3. **Debezium部署**：将Debezium作为Kafka Connect连接器部署，并进行适当的性能调优，包括生产者批处理大小和压缩设置。  

4. **应用端实现**：

   - 在每个应用服务器上使用`HashSet`存储`ShopId`。

   - 实现Kafka消费者，订阅`ShopId`变更主题，并配置为精确一次处理语义（`read_committed`隔离级别）。  

   - 实现`ConsumerRebalanceListener`，在分区撤销时清理或刷新相关缓存，并在分区分配时重新加载数据，以确保重新平衡期间的状态管理。  

   - 配置消费者组使用协作式重新平衡协议和粘性分区分配器，以最小化重新平衡的影响。  

5. **持续监控**：密切监控Kafka消费者延迟（lag），以评估`ShopId`列表的实时性。设置警报以在延迟超出可接受阈值时及时发现问题。同时，监控MySQL和Kafka集群的I/O、CPU和内存使用情况，确保系统资源充足。  

通过遵循上述设计和实施建议，系统将能够高效、可靠地处理高吞吐量的消息过滤任务，并确保分布式环境中`ShopId`数据的一致性。
